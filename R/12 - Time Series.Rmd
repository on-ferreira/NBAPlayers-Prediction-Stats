---
title: "12 - Time Series"
output: html_document
date: "2023-09-25"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(remotes)
remotes::install_github(paste0("rstudio/", c("reticulate", "tensorflow", "keras")))
library(reticulate)
#reticulate::install_miniconda() # skip this if you want to self-install conda or use venv
#keras::install_keras()

library(dplyr)
library(purrr)
library(lubridate)
library(readr)
library(ggplot2)
library(tensorflow)
tf_version()
library(zoo)
library(xts)
library(forecast)
library(keras)
```

Caso seja a primeira vez, delete o "eval=FALSE" do chunk abaixo.

```{r, eval=FALSE}
df_2016_2022 <- read_csv("data/DFwithHourandLocation.csv")  
df_2023 <- read_csv("data/2023-DF.csv")
df_merged <- rbind(df_2016_2022, df_2023)
df_merged
write.csv(df_merged, file = "data/2016-2023-raw-csv.csv", row.names = FALSE)

```

Após isso, passei o "2016-2023-raw-csv.csv" no 00-Cleaner para que possa
começar as análises das séries temporais.

```{r, eval=FALSE}
df <- read_csv("data/2016-2023-cleaned-csv.csv")
df
```

Vou selecionar os jogadores do top 10 para fazer a analise das série
temporais deles, depois vou expandir a ideia para o resto dos jogadores.

```{r, eval=FALSE}
top10 <- read_csv("data/top10.csv")

df_top10 <- subset(df, Name %in% top10$Player)


```

Agora plottando as séries temporais deles.

```{r, eval=FALSE}
# Crie um diretório para salvar os gráficos individuais, se desejado
dir.create("graficos_individuais", showWarnings = FALSE)

for (jogador in top10$Player) {
  # Filtrar o dataframe apenas para o jogador atual
  df_jogador <- subset(df, Name == jogador)
  
  # Criar o gráfico de série temporal para o jogador atual
  p <- ggplot(df_jogador, aes(x = date, y = PTS)) +
    geom_line() +
    labs(x = "Data do Jogo", y = "Pontos (PTS)") +
    ggtitle(paste("Série Temporal de PTS para", jogador))
  
  # Salvar o gráfico individualmente (opcional)
  ggsave(filename = paste("graficos_individuais/", jogador, ".png", sep = ""), plot = p)
  
  # Imprimir o gráfico na tela (opcional)
  print(p)
}
```

Minha ideia é de criar uma espécie personalizada de data: numero do jogo
na season - mes da season - ano da season. Preciso entender melhor como
isso vai performar dentro da TimeSeries, se colocar apenas numero do
jogo - ano da season vai ser melhor.

Antes disso, vou passar o df "data/2016-2023-cleaned-csv.csv" no
pre-processamento do WTP, para ter as colunas que quero testar no
arimaX, usando exogenous = Colunas do WTP.

Vou manter as colunas originais do df, pensando em fazer uma
multivariate timeseries para ter vários valores sobre a performance do
jogador por jogo.

```{r}
df_wtp <- read_csv("data/2016-2023-wtp.csv")
df_wtp



player_name <- "nikola_jokic"

```

```{r}

df_lebron <- df_wtp %>%
  filter(Name == "lebron_james")

df_lebron <- df_lebron %>%
  group_by(season) %>%
  mutate(GameNo = row_number()) %>%
  ungroup()

ggplot(df_lebron, aes(x = GameNo, y = PTS, color = factor(season))) +
  geom_line() +
  labs(title = "Pontuação (PTS) por Número do Jogo (GameNo) por Temporada (Season) para Lebron James",
       x = "Número do Jogo",
       y = "Pontuação (PTS)") +
  theme_minimal() +
  xlim(0, 82)  # Define o limite do eixo X entre 0 e 82 jogos que é a quantidade de jogos em uma season excluindo playoff e play-in

```

Ficou muito dificil de entender o gráfico, olhando a principio me parece
um gráfico de Noise stationary, vou plotar ano a ano para ter uma visão
melhor.

```{r}

ggplot(df_lebron, aes(x = GameNo, y = PTS, color = factor(season))) +
  geom_line() +
  labs(title = "Pontuação (PTS) por Número do Jogo (GameNo) por Temporada (Season)",
       x = "Número do Jogo",
       y = "Pontuação (PTS)") +
  theme_minimal() +
  xlim(0, 82) +  # Define o limite do eixo X entre 0 e 82 jogos
  facet_wrap(~ season, scales = "free")  # Cria um gráfico para cada temporada

```

```{r}
unique_seasons <- unique(df_lebron$season)


for (s in unique_seasons) {
  # Use suppressWarnings para evitar que os warnings sejam impressos
  suppressWarnings({
    p <- ggplot(df_lebron %>% filter(season == s), aes(x = GameNo, y = PTS)) +
      geom_point(aes(color = factor(home))) +
      geom_line(aes(group = 1), linetype = "dashed") + 
      labs(title = paste("Pontuação (PTS) por Número do Jogo (GameNo) - Temporada", s),
           x = "Número do Jogo",
           y = "Pontuação (PTS)") +
      theme_minimal() +
      xlim(0, 82) +
      ylim(0,60)

    print(p)
  })
}

```

Testando as bibliotecas xts forecast para modelos de time series.
"Before we start using black-box deep learning models to solve the
temperatureprediction problem, let's try a simple, common-sense
approach. It will serve as a sanity check, and it will establish a
baseline that we'll have to beat to demonstrate the usefulness of
more-advanced machine learning models"

```{r}

# Converta a coluna 'date' para um formato de data apropriado
df_wtp$date <- as.POSIXct(df_wtp$date)

df_player <- df_wtp %>%
  filter(Name == player_name)

# Especifique a proporção de dados a serem usados para treinamento (por exemplo, 80%)
train_proportion <- 0.8

# Calcule o índice para dividir os dados
split_index <- floor(nrow(df_player) * train_proportion)

# Crie os conjuntos de treinamento e teste
train_data <- df_player[1:split_index, ]
test_data <- df_player[(split_index + 1):nrow(df_player), ]

# Converta os dados de treinamento para um objeto xts
train_time_series <- xts(train_data$PTS, order.by = train_data$date)
plot(train_time_series, main = "Irregular Time Series of PTS", ylab = "PTS", xlab = "Date")

# Ajuste um modelo ARIMA aos dados de treinamento
arima_model <- auto.arima(train_time_series)

# Preveja os valores para os dados de teste
predicted_values <- forecast(arima_model, h = length(test_data$PTS))

# Converta os dados de teste para um objeto xts
test_time_series <- xts(test_data$PTS, order.by = test_data$date)

# Compare os valores previstos com os valores reais nos dados de teste
accuracy <- accuracy(predicted_values, test_time_series)
print(accuracy)

# Converta os objetos xts em data frames para facilitar a plotagem
actual_train_data <- data.frame(Date = index(train_time_series), PTS = coredata(train_time_series))
predicted_train_data <- data.frame(Date = index(train_time_series), PTS = fitted(arima_model))

# Crie um data frame para plotar os valores reais e previstos
combined_train_data <- rbind(actual_train_data, predicted_train_data)
combined_train_data$Type <- c(rep("Actual", nrow(actual_train_data)), rep("Predicted", nrow(predicted_train_data)))

# Plot the actual and predicted values on the same graph for the training period
ggplot(combined_train_data, aes(x = Date, y = PTS, color = Type)) +
  geom_line() +
  labs(title = "Actual vs. Predicted PTS - Train Period",
       x = "Date",
       y = "PTS") +
  theme_minimal()

# Converta os objetos xts em data frames para facilitar a plotagem
actual_test_data <- data.frame(Date = index(test_time_series), PTS = coredata(test_time_series))
predicted_test_data <- data.frame(Date = index(test_time_series), PTS = coredata(predicted_values$mean))

# Crie um data frame para plotar os valores reais e previstos
combined_test_data <- rbind(actual_test_data, predicted_test_data)
combined_test_data$Type <- c(rep("Actual", nrow(actual_test_data)), rep("Predicted", nrow(predicted_test_data)))

# Plot the actual and predicted values on the same graph for the test period
ggplot(combined_test_data, aes(x = Date, y = PTS, color = Type)) +
  geom_line() +
  labs(title = "Actual vs. Predicted PTS - Test Period",
       x = "Date",
       y = "PTS") +
  theme_minimal()

```

O primeiro modelo se mostra bastante ineficaz, como esperado, vou
refazer adicionando as colunas do wtp e ver se tem um resultado melhor
ou pior. Achei um comentário interessante no stackoverflow sobre esse
tipo de problema: "I understand your problem. I currently work on a
similar problem. (We have appointment schedules which are recurrent
every week, but the schedules are often overruled if required, meaning
irregular time series). I switched to machine learning, implemented a
boosted regression tree, but there are many others. Time series are only
appropriate if you think time aspects are responsible for the noise in
data, but there are often so many different factors, like maybe the
weather, or the product type, or interaction terms between two variables
that might explain part of the noise."

```{r}

# Converta a coluna 'date' para um formato de data apropriado
df_wtp$date <- as.POSIXct(df_wtp$date)

df_player <- df_wtp %>%
  filter(Name == player_name)

# Especifique a proporção de dados a serem usados para treinamento (por exemplo, 80%)
train_proportion <- 0.8

# Calcule o índice para dividir os dados
split_index <- floor(nrow(df_player) * train_proportion)

# Crie os conjuntos de treinamento e teste
train_data <- df_player[1:split_index, ]
test_data <- df_player[(split_index + 1):nrow(df_player), ]

# Converta os dados de treinamento para um objeto xts
train_time_series <- xts(train_data$PTS, order.by = train_data$date)
plot(train_time_series, main = "Irregular Time Series of PTS", ylab = "PTS", xlab = "Date")

# Crie um data frame com as variáveis exógenas (todas as colunas iniciadas com "L5_" e "L10_", e "rest_days")
exog_vars <- as.matrix(train_data %>%
  select(starts_with("L5_"), starts_with("L10_"), "rest_days", "season"))

# Ajuste um modelo ARIMA aos dados de treinamento com variáveis exógenas
x_arima_model <- auto.arima(train_time_series, seasonal = TRUE, xreg = exog_vars)

# Preveja os valores para os dados de teste
exog_vars_test <- as.matrix(test_data %>%
  select(starts_with("L5_"), starts_with("L10_"), "rest_days", "season"))
predicted_values <- forecast(x_arima_model, xreg = exog_vars_test)

# Converta os dados de teste para um objeto xts
test_time_series <- xts(test_data$PTS, order.by = test_data$date)

# Compare os valores previstos com os valores reais nos dados de teste
accuracy <- accuracy(predicted_values, test_time_series)
print(accuracy)

# Converta os objetos xts em data frames para facilitar a plotagem
actual_train_data <- data.frame(Date = index(train_time_series), PTS = coredata(train_time_series))
predicted_train_data <- data.frame(Date = index(train_time_series), PTS = fitted(x_arima_model))

# Crie um data frame para plotar os valores reais e previstos
combined_train_data <- rbind(actual_train_data, predicted_train_data)
combined_train_data$Type <- c(rep("Actual", nrow(actual_train_data)), rep("Predicted", nrow(predicted_train_data)))

# Plot the actual and predicted values on the same graph for the training period
ggplot(combined_train_data, aes(x = Date, y = PTS, color = Type)) +
  geom_line() +
  labs(title = "Actual vs. Predicted PTS - Train Period",
       x = "Date",
       y = "PTS") +
  theme_minimal()

# Converta os objetos xts em data frames para facilitar a plotagem
actual_test_data <- data.frame(Date = index(test_time_series), PTS = coredata(test_time_series))
predicted_test_data <- data.frame(Date = index(test_time_series), PTS = coredata(predicted_values$mean))

# Crie um data frame para plotar os valores reais e previstos
combined_test_data <- rbind(actual_test_data, predicted_test_data)
combined_test_data$Type <- c(rep("Actual", nrow(actual_test_data)), rep("Predicted", nrow(predicted_test_data)))

# Plot the actual and predicted values on the same graph for the test period
ggplot(combined_test_data, aes(x = Date, y = PTS, color = Type)) +
  geom_line() +
  labs(title = "Actual vs. Predicted PTS - Test Period",
       x = "Date",
       y = "PTS") +
  theme_minimal()


```

Considerações: O modelo criado não lida muito bem com as altas
volatilidades da pontuação de um jogador, enquanto as pontuações tendem
a variar muito, o modelo tende a variar pouco, as vezes na mesma
direção, as vezes em direções opostas. Fiz o teste com jogadores
diferentes e acontece o mesmo com todos eles.

```{r}

df_player <- df_wtp %>%
  filter(Name == player_name)

num_train_samples <- round(nrow(df_player) * .5) 
num_val_samples <- round(nrow(df_player) * 0.25) 
num_test_samples <- nrow(df_player) - num_train_samples - num_val_samples 

train_df <- df_player[seq(num_train_samples), ]
val_df <- df_player[seq(from = nrow(train_df) + 1, length.out = num_val_samples),]
test_df <- df_player[seq(to = nrow(df_player), length.out = num_test_samples), ]

cat("num_train_samples:", nrow(train_df), "\n")
cat("num_val_samples:", nrow(val_df), "\n")
cat("num_test_samples:", nrow(test_df), "\n")

#Normalizing the data

input_data_colnames <- colnames(df_player %>%
  select(starts_with("L5_"), starts_with("L10_"), "rest_days", "ppm"))

# Calculate mean and standard deviation for each column in input_data_colnames
mean_values <- lapply(train_df[input_data_colnames], mean)
sd_values <- lapply(train_df[input_data_colnames], sd)

# Combine the mean and standard deviation values into a dataframe
normalization_values <- data.frame(
  Column = names(train_df[input_data_colnames]),
  Mean = unlist(mean_values),
  SD = unlist(sd_values)
)

# Print the normalization values
normalization_values

normalize_input_data <- function(df) {
  normalize <- function(x, center, scale) {
    (x - center) / scale
  }
  
  for (col_nm in input_data_colnames) {
    col_nv <- normalization_values[normalization_values$Column == col_nm,]
    df[[col_nm]] <- normalize(df[[col_nm]], col_nv$Mean, col_nv$SD)
  }
  
  return(df)
}

# Apply the normalization function to your dataframe (e.g., train_df)
normalized_train_df <- normalize_input_data(train_df)
```

Dados do exemplo: 1 leitura a cada hora. sequence_length = 5 dias. Delay
= 6 dias -1 hora sampling_rate \<- 6 sequence_length \<- 120 delay \<-
sampling_rate \* (sequence_length + 24 - 1) batch_size \<- 256

```{r}
sampling_rate <- 6
sequence_length <- 10
delay <- sampling_rate * (sequence_length  - 1)
batch_size <- 128

# Define the function to prepare inputs and targets
df_to_inputs_and_targets <- function(df, delay) {
  inputs <- df[input_data_colnames] %>%
    normalize_input_data() %>%
    as.matrix() 
  
  targets <- as.array(df$PTS) 

  list(
    head(inputs, -delay), 
    tail(targets, -delay) 
  )
}

# Define the function to create a time series dataset
make_dataset <- function(df) {
  inputs_and_targets <- df_to_inputs_and_targets(df, delay)
  inputs <- inputs_and_targets[[1]]
  targets <- inputs_and_targets[[2]]

  timeseries_dataset_from_array(
    inputs, targets,
    sampling_rate = sampling_rate,
    sequence_length = sequence_length,
    shuffle = TRUE,
    batch_size = batch_size
  )
}

train_dataset <- make_dataset(train_df)
val_dataset <- make_dataset(val_df)
test_dataset <- make_dataset(test_df)

```

Seguindo os passos do livro "Deep Learning with R", primeiro fazemos um
modelo simplista para ter como parametro de métricas.

```{r}
library(tfdatasets)

options(tensorflow.extract.warn_negatives_pythonic = FALSE)

#Essas funções abaixo não estão vindo embutidas no tfdatasets por algum motivo e são necessárias para rodar o código abaixo.

as_py_function <- function(x) {
  if (inherits(x, "python.builtin.function")) {
    x
  } else {
    rlang::as_function(x)
  }
}

as_integer_tensor <- function(x, dtype = tf$int64) {

  # recurse over lists
  if (is.list(x) || (is.numeric(x) && length(x) > 1))
    lapply(x, function(elem) as_integer_tensor(elem, dtype))
  else if (is.null(x))
    x
  else if (is_tensor(x))
    tf$cast(x, dtype = dtype)
  else
    tf$constant(as.integer(x), dtype = dtype)
}




###
c(samples, targets) %<-% iter_next(as_iterator(train_dataset))
cat("samples shape: ", format(samples$shape), "\n",
"targets shape: ", format(targets$shape), "\n", sep = "")



```

```{r}

#Training and evaluating a densely connected model

ncol_input_data <- length(input_data_colnames)
inputs <- layer_input(shape = c(sequence_length, ncol_input_data))
outputs <- inputs %>%
            layer_flatten() %>%
            layer_dense(16, activation = "relu") %>%
            layer_dense(1)

model <- keras_model(inputs, outputs)

early_stopping <- callback_early_stopping(
  monitor = "val_loss",  # Monitor validation loss
  patience = 10,         # Number of epochs with no improvement before stopping
  verbose = 1            # Show messages about early stopping
)

model %>%
    compile(
      optimizer = "rmsprop",
      loss = "mse",
      metrics = list("mae", "mse") 
    )

history <- model %>%
            fit(train_dataset,
            epochs = 10,
            validation_data = val_dataset,
            callbacks = list(early_stopping))

model_weights_file <- "simple_model.keras"

save_model_weights_hdf5(model, model_weights_file)

eval_model <- evaluate(model, test_dataset)
mae <- eval_model[["mae"]]
mse <- eval_model[["mse"]]
rmse <- sqrt(mse)  # Calculate RMSE from MSE

sprintf("Test MAE: %.2f", mae)
sprintf("Test MSE: %.2f", mse)
sprintf("Test RMSE: %.2f", rmse)  # Print RMSE

#Plotting results
plot(history, metrics = "mae")
```

Estou com problemas na arquitetura de rede neural convolucional abaixo,
ValueError: One of the dimensions in the output is \<= 0 due to
downsampling in conv1d_23. Consider increasing the input size. Received
input shape [None, 10, 37] which would produce output shape with a zero
or negative value in a dimension.

```{r, eval=FALSE}

inputs <- layer_input(shape = c(sequence_length, ncol_input_data))

outputs <- inputs %>%
          layer_conv_1d(8, 12, activation = "relu") %>%
          layer_max_pooling_1d(2) %>%
          layer_conv_1d(8, 6, activation = "relu") %>%
          layer_max_pooling_1d(2) %>%
          layer_conv_1d(8, 3, activation = "relu") %>%
          layer_global_average_pooling_1d() %>%
          layer_dense(1)

model <- keras_model(inputs, outputs)

early_stopping <- callback_early_stopping(
  monitor = "val_loss",  # Monitor validation loss
  patience = 10,         # Number of epochs with no improvement before stopping
  verbose = 1            # Show messages about early stopping
)

model %>%
    compile(
      optimizer = "rmsprop",
      loss = "mse",
      metrics = list("mae", "mse") 
    )

history <- model %>% fit(
      train_dataset,
      epochs = 50,
      validation_data = val_dataset,
      callbacks = list(early_stopping)
      )

model_weights_file <- "conv_model.keras"

save_model_weights_hdf5(model, model_weights_file)

eval_model <- evaluate(model, test_dataset)
mae <- eval_model[["mae"]]
mse <- eval_model[["mse"]]
rmse <- sqrt(mse)  # Calculate RMSE from MSE

sprintf("Test MAE: %.2f", mae)
sprintf("Test MSE: %.2f", mse)
sprintf("Test RMSE: %.2f", rmse)  # Print RMSE

plot(history)

```

```{r}

inputs <- layer_input(shape = c(sequence_length, ncol_input_data))
outputs <- inputs %>%
          layer_lstm(16) %>%
          layer_dense(1)
model <- keras_model(inputs, outputs)

early_stopping <- callback_early_stopping(
  monitor = "val_loss",  # Monitor validation loss
  patience = 10,         # Number of epochs with no improvement before stopping
  verbose = 1            # Show messages about early stopping
)

model %>%
    compile(
      optimizer = "rmsprop",
      loss = "mse",
      metrics = list("mae", "mse") 
    )

history <- model %>% fit(
        train_dataset,
        epochs = 50,
        validation_data = val_dataset,
        callbacks = list(early_stopping)
        )

model_weights_file <- "lstm_model.keras"

save_model_weights_hdf5(model, model_weights_file)

eval_model <- evaluate(model, test_dataset)
mae <- eval_model[["mae"]]
mse <- eval_model[["mse"]]
rmse <- sqrt(mse) 

sprintf("Test MAE: %.2f", mae)
sprintf("Test MSE: %.2f", mse)
sprintf("Test RMSE: %.2f", rmse)  # Print RMSE


plot(history)
```

```{r}
#Listing 10.21 Training and evaluating a dropout-regularized LSTM

inputs <- layer_input(shape = c(sequence_length, ncol_input_data))
outputs <- inputs %>%
        layer_lstm(32, recurrent_dropout = 0.25) %>%
        layer_dropout(0.5) %>%
        layer_dense(1)

model <- keras_model(inputs, outputs)

early_stopping <- callback_early_stopping(
  monitor = "val_loss",  # Monitor validation loss
  patience = 10,         # Number of epochs with no improvement before stopping
  verbose = 1            # Show messages about early stopping
)

model %>%
    compile(
      optimizer = "rmsprop",
      loss = "mse",
      metrics = list("mae", "mse") 
    )

history <- model %>% fit(
    train_dataset,
    epochs = 50,
    validation_data = val_dataset,
    callbacks = list(early_stopping)
)

model_weights_file <- "lstm_dropout_model.keras"

save_model_weights_hdf5(model, model_weights_file)

eval_model <- evaluate(model, test_dataset)
mae <- eval_model[["mae"]]
mse <- eval_model[["mse"]]
rmse <- sqrt(mse)  

sprintf("Test MAE: %.2f", mae)
sprintf("Test RMSE: %.2f", rmse) 



plot(history)

```

```{r}
#Listing 10.22 Training and evaluating a dropout-regularized, stacked GRU model

inputs <- layer_input(shape = c(sequence_length, ncol_input_data))
outputs <- inputs %>%
          layer_gru(32, recurrent_dropout = 0.5, return_sequences = TRUE) %>%
          layer_gru(32, recurrent_dropout = 0.5) %>%
          layer_dropout(0.5) %>%
          layer_dense(1)

early_stopping <- callback_early_stopping(
  monitor = "val_loss",  # Monitor validation loss
  patience = 10,         # Number of epochs with no improvement before stopping
  verbose = 1            # Show messages about early stopping
)

model %>%
    compile(
      optimizer = "rmsprop",
      loss = "mse",
      metrics = list("mae", "mse") 
    )

history <- model %>% fit(
    train_dataset,
    epochs = 50,
    validation_data = val_dataset,
    callbacks = list(early_stopping)
)


model_weights_file <- "lstm_dropout_gru_model.keras"

save_model_weights_hdf5(model, model_weights_file)

eval_model <- evaluate(model, test_dataset)
mae <- eval_model[["mae"]]
mse <- eval_model[["mse"]]
rmse <- sqrt(mse)  

sprintf("Test MAE: %.2f", mae)
sprintf("Test RMSE: %.2f", rmse) 

plot(history)


```

Lembrando que os resultados de nikola_jokic com o modelo de
Random_Forest treinado tinha métricas de RMSE = 6.57 e RSQ = 28.77, logo
chego a conclusão de que analisar levando em consideração o tempo, não
esteja rendendo bons resultados.

O modelo sarimax do auto.arima teve resultados mais significativos que
as redes neurais. Isso me leva a dois pensamentos: - Menos é mais - Eu
possivelmente fiz algo errado nas redes neurais
