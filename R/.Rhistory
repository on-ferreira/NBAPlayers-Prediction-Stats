# Box plot of points by team
ggplot(df, aes(x = team, y = PTS)) +
geom_boxplot() +
xlab("Team") +
ylab("Points") +
ggtitle("Points by Team") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Line plot of points over time
df_season <- df %>% group_by(season) %>% summarize(avg_points = mean(PTS))
ggplot(df_season, aes(x = season, y = avg_points)) +
geom_line() +
xlab("Season") +
ylab("Average Points") +
ggtitle("Average Points per Season") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Assuming your dataframe is named df
nested_data <- df %>%
group_by(Name) %>%
nest(.key="data")
# Print the nested data
nested_data
# Define a function to calculate the sum of MP
sum_MP <- function(data) {
sum(data$MP)
}
# Define a function to count the occurrences of the player
count <- function(data) {
nrow(data)
}
nested_data <- nested_data %>%
mutate(sum_MP = map_dbl(data, sum_MP),
count = map_int(data, count))
# Print the nested data with sum_MP and count columns
nested_data
# Filter the nested data for "joel_embiid"
player_data <- nested_data[nested_data$Name == "joel_embiid", ]$data
# Print the nested data for "joel_embiid"
print(player_data)
# Function to calculate rest days
calculate_rest_days <- function(df) {
df$rest_days <- c(0, diff(df$date))
return(df)
}
# Apply the calculate_rest_days function to nested_data
nested_data <- nested_data %>%
mutate(data = purrr::map(data, ~ calculate_rest_days(.)))
#Creating the columns next_opp and next_PTS
nested_data <- nested_data %>%
mutate(data = map(data, ~ {
df <- .x
df$next_opp <- c(df$opp[-1], NA)
df$next_PTS <- c(df$PTS[-1], NA)
df
}))
# View the updated nested_data with the rest_days column within each nested dataset
nested_data
player_name <- "joel_embiid"
# Filter the nested data for "joel_embiid"
joel_embiid_data <- nested_data %>%
filter(Name == player_name) %>%
pull(data) %>%
pluck(1)
# Print the nested data for "joel_embiid"
print(joel_embiid_data)
clone_nested <- nested_data %>%
filter(count > 20)
lm_model <- function(data) {
# First, remove factors with only one level from the predictors [Ex: When the player played in only 1 team]
predictors <- select(data, where(~ is.factor(.) && n_distinct(.) > 1))
#First we delete the last row of the data that will contain next_PTS = NAN
data <- data %>% slice(-n())
# Ensure that the `strata` column is present and has compatible sizes
if (!"season_month" %in% colnames(data) || !is.numeric(data$season_month)) {
return(NULL)
}
# Fit the linear regression model
set.seed(502)
data_split <- initial_split(data, prop = 0.80, strata = season_month)
data_train <- training(data_split)
data_test <- testing(data_split)
lm_model <- linear_reg() %>% set_engine("lm")
lm_wflow <-
workflow() %>%
add_model(lm_model) %>%
add_variables(outcome = next_PTS, predictors = names(predictors))
lm_fit <- fit(lm_wflow, data_train)
lm_fit
}
clone_nested <- clone_nested %>%
mutate(model = map(data,lm_model))
clone_nested
split_data <- function(data) {
set.seed(502)
data_split <- initial_split(data, prop = 0.80, strata = season_month)
data_train <- training(data_split)
data_test <- testing(data_split)
list(data_train = data_train, data_test = data_test)
}
clone_nested <- clone_nested %>%
mutate(splitado = map(data,split_data))
clone_nested
clone_nested <- clone_nested %>%
mutate(data_train = map(splitado, pluck, "data_train"),
data_test = map(splitado, pluck, "data_test"))
clone_nested
clone_nested <- clone_nested %>%
select(-splitado)
clone_nested
simple_lm <- function(data,data_train){
recipe_obj <- recipe(next_PTS ~ ., data = data_train) %>%
step_select(where(~ is.factor(.) && n_distinct(.) > 1)) %>%
step_slice(-n()) %>%
step_dummy(all_nominal_predictors(), -all_outcomes())
recipe_obj
}
clone_nested <- clone_nested %>%
mutate(simple = map2(data,data_train, simple_lm))
clone_nested
recipe_model <- function(recipe) {
lm_model <- linear_reg() %>% set_engine("lm")
lm_wflow <-
workflow() %>%
add_model(lm_model) %>%
add_recipe(recipe)
lm_wflow
}
clone_nested <- clone_nested %>%
mutate(recipe_wflow = map(simple, ~recipe_model(.x)))
clone_nested
test <- clone_nested %>%
filter(Name == "joel_embiid") %>%
pull(simple)
test
# Define the player names
player_names <- c("joel_embiid", "nikola_jokic")
# Filter the nested data for specific players
filtered_data <- nested_data %>%
filter(Name %in% player_names) %>%
mutate(data = map(data, ~ .x %>% unnest(cols = c(PTS, hour_float))))
# Combine the filtered and unnested data into a single dataframe
combined_data <- bind_rows(filtered_data$data, .id = "Name") %>%
mutate(Name = recode(Name, "1" = "nikola_jokic", "2" = "joel_embiid")) %>%
group_by(Name, hour_float, PTS) %>%
mutate(count = n())
# Print the combined data
print(combined_data)
# Plot the graph
ggplot(combined_data, aes(x = hour_float, y = PTS, color = Name, size = count)) +
geom_point() +
labs(x = "Hour", y = "PTS", color = "Player", size = "FrequÃªncia") +
scale_color_manual(values = c("joel_embiid" = "red", "nikola_jokic" = "blue"))
# Define a function to perform the statistical analysis for each nested group
hour_model <- function(data) {
# Fit the linear regression model
lm(PTS ~ hour_float, data = data)
}
models <- map(nested_data$data, hour_model)
#Cloning the nested_data for this battery of tests
clone_nested2 <- nested_data %>%
mutate(hourmodel = map(data,hour_model))
clone_nested2
clone_nested2 <- clone_nested2 %>%
mutate(
resids = map2(data,hourmodel,add_residuals)
)
clone_nested2
resids <- unnest(clone_nested2, resids)
resids
resids %>%
ggplot(aes(hour_float, resid)) +
geom_line(aes(group = Name), alpha = 1 / 3) +
geom_smooth(se = FALSE)
#> `geom_smooth()` using method = 'gam'
resids %>%
ggplot(aes(hour_float, resid, group = Name)) +
geom_line(alpha = 1 / 3) +
facet_wrap(~team)
glance <- clone_nested2 %>%
mutate(glance = map(hourmodel,broom::glance)) %>%
unnest(glance, .drop = TRUE)
glance
glance %>%
arrange(r.squared)
good_fit <- filter(glance, abs(r.squared) > 0.75 )
good_fit
unnested_good_fit <- good_fit %>%
unnest(cols = c(data))
unnested_good_fit
name_counts <- unnested_good_fit %>%
group_by(Name, count) %>%
summarise() %>%
ungroup() %>%
arrange(desc(count))
name_counts
numerical_df <- df %>%
mutate(team = as.numeric(as.factor(team)),
opp = as.numeric(as.factor(opp)))
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df[c("PTS","AST", "TRB", "opp","team","season")])
corrplot(correlation_matrix, method = "circle")
numerical_df <- df %>%
mutate(team = as.numeric(as.factor(team)),
opp = as.numeric(as.factor(opp)))
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
df <- read_csv("data/wtp.csv")
# Imprimir nomes das colunas restantes
print(names(df))
numerical_df <- df %>%
mutate(team = as.numeric(as.factor(team)),
opp = as.numeric(as.factor(opp)))
numerical_df <- df %>%
mutate(team = as.numeric(as.factor(team)),
opp = as.numeric(as.factor(opp)))
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
print(names(df))
# Remover colunas relacionadas a ORB, DRB, TRB, AST, STL, BLK
df <- df[, -c(23:32)]
print(names(df))
numerical_df <- df %>%
mutate(team = as.numeric(as.factor(team)),
opp = as.numeric(as.factor(opp)))
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df[c("PTS","MP", "home", "opp","team","season")])
corrplot(correlation_matrix, method = "circle")
numerical_df <- df[, !(names(df) %in% c("opp", "team"))]
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
numerical_df <- df[, sapply(df, is.numeric) & !(names(df) %in% c("opp", "team"))]
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
corrplot(correlation_matrix, method = "circle")
high_correlation <- which(abs(correlation_matrix) > 0.8 & correlation_matrix != 1, arr.ind = TRUE)
for (i in 1:nrow(high_correlation)) {
row <- high_correlation[i, 1]
col <- high_correlation[i, 2]
cor_value <- correlation_matrix[row, col]
col_name1 <- colnames(correlation_matrix)[row]
col_name2 <- colnames(correlation_matrix)[col]
print(paste("Absolute Correlation between", col_name1, "and", col_name2, ":", cor_value))
}
print(names(df))
# Remover colunas relacionadas a ORB, DRB, TRB, AST, STL, BLK
df <- df[, -c(23:34)]
df <- read_csv("data/wtp.csv")
# Remover colunas relacionadas a ORB, DRB, TRB, AST, STL, BLK
df <- df[, -c(23:34)]
print(names(df))
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
numerical_df <- df[, sapply(df, is.numeric) & !(names(df) %in% c("opp", "team"))]
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
corrplot(correlation_matrix, method = "circle")
high_correlation <- which(abs(correlation_matrix) > 0.8 & correlation_matrix != 1, arr.ind = TRUE)
for (i in 1:nrow(high_correlation)) {
row <- high_correlation[i, 1]
col <- high_correlation[i, 2]
cor_value <- correlation_matrix[row, col]
col_name1 <- colnames(correlation_matrix)[row]
col_name2 <- colnames(correlation_matrix)[col]
print(paste("Absolute Correlation between", col_name1, "and", col_name2, ":", cor_value))
}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(purrr)
library(readr)
library(tidymodels)
tidymodels_prefer()
library(recipes)
library(conflicted)
library(usemodels)
library(xgboost)
library(ggrepel)
library(corrr)
library(tidyposterior)
library(rstanarm)
library(baguette)
library(ranger)
library(kernlab)
library(kknn)
library(glmnet)
# speed up computation with parrallel processing (optional)
library(doParallel)
all_cores <- parallel::detectCores(logical = FALSE)
#Create cluster with desired number of cores, leave one open for the machine
#core processes
cl <- makeCluster(all_cores[1]-1)
registerDoParallel(cores = all_cores)
df <- read_csv("data/wtp.csv")
df
print(names(df))
# Remover colunas relacionadas a ORB, DRB, TRB, AST, STL, BLK
df <- df[, -c(23:34)]
print(names(df))
numerical_df <- df[, sapply(df, is.numeric) & !(names(df) %in% c("opp", "team"))]
# Correlation matrix with teams and seasonal data
correlation_matrix <- cor(numerical_df)
corrplot(correlation_matrix, method = "circle")
high_correlation <- which(abs(correlation_matrix) > 0.8 & correlation_matrix != 1, arr.ind = TRUE)
for (i in 1:nrow(high_correlation)) {
row <- high_correlation[i, 1]
col <- high_correlation[i, 2]
cor_value <- correlation_matrix[row, col]
col_name1 <- colnames(correlation_matrix)[row]
col_name2 <- colnames(correlation_matrix)[col]
print(paste("Absolute Correlation between", col_name1, "and", col_name2, ":", cor_value))
}
player_df <- df[df$Name == "nikola_jokic", ]
player_df
player_df$home <- NULL
player_df$Name <- NULL
player_df$team <- NULL
player_df
set.seed(502)
player_df_split <- initial_split(player_df, prop = 0.80, strata = season_month)
player_df_train <- training(player_df_split)
player_df_test <- testing(player_df_split)
set.seed(1001)
player_folds <- vfold_cv(player_df_train, v = 10, repeats = 5)
new_rec <-
recipe(PTS ~ ., data = player_df_train) %>%
step_dummy(all_nominal_predictors())  %>%
step_zv(all_predictors())
new_normalized_rec <- new_rec %>%
step_normalize(all_numeric_predictors())
new_rec
linear_reg_spec <-
linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
nnet_spec <-
mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%
set_engine("nnet", MaxNWts = 2600) %>%
set_mode("regression")
mars_spec <-
mars(prod_degree = tune()) %>% #<- use GCV to choose terms
set_engine("earth") %>%
set_mode("regression")
svm_r_spec <-
svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
svm_p_spec <-
svm_poly(cost = tune(), degree = tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
knn_spec <-
nearest_neighbor(neighbors = tune(), dist_power = tune(), weight_func = tune()) %>%
set_engine("kknn") %>%
set_mode("regression")
cart_spec <-
decision_tree(cost_complexity = tune(), min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("regression")
rf_spec <-
rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
cubist_spec <-
cubist_rules(committees = tune(), neighbors = tune()) %>%
set_engine("Cubist")
nnet_param <-
nnet_spec %>%
extract_parameter_set_dials() %>%
recipes::update(hidden_units = hidden_units(c(1, 27)))
normalized <-
workflow_set(
preproc = list(simple = new_rec),
models = list(SVM_radial = svm_r_spec, SVM_poly = svm_p_spec,
KNN = knn_spec, neural_network = nnet_spec)
)
normalized
normalized %>% extract_workflow(id = "simple_KNN")
normalized <-
normalized %>%
option_add(param_info = nnet_param, id = "simple_neural_network")
normalized
normalized <-
normalized %>%
option_add(param_info = nnet_param, id = "simple_neural_network")
normalized
library(rules)
model_vars <-
workflow_variables(outcomes = PTS,
predictors = everything())
no_pre_proc <-
workflow_set(
preproc = list(simple = model_vars),
models = list(MARS = mars_spec,
CART = cart_spec,
RF = rf_spec,
Cubist = cubist_spec)
)
no_pre_proc
with_features <-
workflow_set(
preproc = list(norm = new_normalized_rec),
models = list(linear_reg = linear_reg_spec, KNN = knn_spec)
)
all_workflows <-
bind_rows(no_pre_proc, normalized, with_features) %>%
# Make the workflow IDs a little more simple:
mutate(wflow_id = gsub("(simple_)|(normalized_)", "", wflow_id))
all_workflows
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = TRUE
)
grid_ctrl
grid_results <-
all_workflows %>%
workflow_map(
seed = 1503,
resamples = player_folds,
grid = 25,
control = grid_ctrl,
verbose = TRUE
)
grid_results
grid_ctrl <-
control_grid(
save_pred = TRUE,
save_workflow = TRUE
)
full_results_time <-
system.time(
grid_results <-
all_workflows %>%
workflow_map(seed = 1503, resamples = player_folds, grid = 25,
control = grid_ctrl, verbose = TRUE)
)
num_grid_models <- nrow(collect_metrics(grid_results, summarize = FALSE))
grid_results
grid_results %>%
rank_results() %>%
filter(.metric == "rsq") %>%
select(model, .config, rmse = mean, rank)
autoplot(
grid_results,
rank_metric = "rmse", # <- how to order models
metric = "rmse", # <- which metric to visualize
select_best = TRUE # <- one point per workflow
) +
geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +
lims(y = c(3.5, 9.5)) +
theme(legend.position = "none")
autoplot(grid_results, id = "RF", metric = "rmse")
library(finetune)
race_ctrl <-
control_race(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = TRUE
)
race_results <-
all_workflows %>%
workflow_map(
"tune_race_anova",
seed = 1503,
resamples = player_folds,
grid = 25,
control = race_ctrl,
verbose = TRUE
)
race_results
autoplot(
race_results,
rank_metric = "rmse",
metric = "rmse",
select_best = TRUE
) +
geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +
lims(y = c(3.0, 11)) +
theme(legend.position = "none")
matched_results <-
rank_results(race_results, select_best = TRUE) %>%
select(wflow_id, .metric, race = mean, config_race = .config) %>%
inner_join(
rank_results(grid_results, select_best = TRUE) %>%
select(wflow_id, .metric, complete = mean,
config_complete = .config, model),
by = c("wflow_id", ".metric"),
) %>%
filter(.metric == "rmse")
matched_results %>%
ggplot(aes(x = complete, y = race)) +
geom_abline(lty = 3) +
geom_point() +
geom_text_repel(aes(label = model)) +
coord_obs_pred() +
labs(x = "Complete Grid RMSE", y = "Racing RMSE")
best_results <-
race_results %>%
extract_workflow_set_result("Cubist") %>%
select_best(metric = "rmse")
best_results
cubist_test_results <-
race_results %>%
extract_workflow("Cubist") %>%
finalize_workflow(best_results) %>%
last_fit(split = player_df_split)
collect_metrics(cubist_test_results)
cubist_test_results %>%
collect_predictions() %>%
ggplot(aes(x = PTS, y = .pred)) +
geom_abline(color = "gray50", lty = 2) +
geom_point(alpha = 0.5) +
coord_obs_pred() +
labs(x = "observed", y = "predicted")
